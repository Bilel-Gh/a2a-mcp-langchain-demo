# 06 - LangChain et LangGraph

## Table des MatiÃ¨res

1. [Introduction](#introduction)
2. [Qu'est-ce que LangChain ?](#quest-ce-que-langchain)
3. [Qu'est-ce que LangGraph ?](#quest-ce-que-langgraph)
4. [LangChain vs LangGraph](#langchain-vs-langgraph)
5. [Utilisation dans le Projet](#utilisation-dans-le-projet)
6. [IntÃ©gration avec Gemini](#intÃ©gration-avec-gemini)
7. [ReAct Agent Pattern](#react-agent-pattern)
8. [MCP Adapters pour LangChain](#mcp-adapters-pour-langchain)
9. [Exemples Concrets du Projet](#exemples-concrets-du-projet)
10. [RÃ©sumÃ© et Bonnes Pratiques](#rÃ©sumÃ©-et-bonnes-pratiques)

---

## Introduction

**LangChain** et **LangGraph** sont deux bibliothÃ¨ques complÃ©mentaires pour construire des applications avec des LLMs (Large Language Models).

### Pourquoi Ces BibliothÃ¨ques ?

Les LLMs comme GPT, Claude, ou Gemini sont puissants, mais leur intÃ©gration dans des applications rÃ©elles nÃ©cessite :

âŒ **Sans LangChain/LangGraph** :
- Code rÃ©pÃ©titif pour appeler les APIs LLM
- Gestion manuelle des prompts
- Connexion manuelle aux outils externes
- Orchestration complexe de workflows

âœ… **Avec LangChain/LangGraph** :
- Abstractions pour appeler n'importe quel LLM
- Gestion de prompts standardisÃ©e
- IntÃ©gration facile d'outils (tools)
- Workflows multi-Ã©tapes avec Ã©tat

### Dans Notre Projet

Nous utilisons LangChain et LangGraph dans **3 agents** :

1. **Calculator Agent** : LangChain + LangGraph + MCP Tools
2. **Web Search Agent** : LangChain + LangGraph + MCP Tools
3. **Travel Planner Agent** : LangChain uniquement (gÃ©nÃ©ration de texte)

---

## Qu'est-ce que LangChain ?

### DÃ©finition

**LangChain** est un framework pour dÃ©velopper des applications alimentÃ©es par des LLMs. Il fournit des **abstractions** et des **composants rÃ©utilisables** pour :

- Appeler des LLMs (OpenAI, Anthropic, Google, etc.)
- GÃ©rer des prompts
- Connecter des outils (tools)
- GÃ©rer la mÃ©moire et le contexte
- ChaÃ®ner des opÃ©rations

### Architecture de Base

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  LangChain                       â”‚
â”‚                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚    LLMs    â”‚  â”‚   Prompts  â”‚  â”‚   Tools   â”‚ â”‚
â”‚  â”‚  (Gemini,  â”‚  â”‚ (Templates)â”‚  â”‚(Functions)â”‚ â”‚
â”‚  â”‚   GPT...)  â”‚  â”‚            â”‚  â”‚           â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   Chains   â”‚  â”‚   Memory   â”‚  â”‚ Retrieval â”‚ â”‚
â”‚  â”‚ (Sequences)â”‚  â”‚  (Context) â”‚  â”‚   (RAG)   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Composants Principaux

#### 1. LLMs (Language Models)

Abstractions pour appeler diffÃ©rents LLMs avec une interface unifiÃ©e.

```typescript
import { ChatGoogleGenerativeAI } from "@langchain/google-genai";

// CrÃ©er une instance du LLM Gemini
const model = new ChatGoogleGenerativeAI({
  apiKey: process.env.GEMINI_API_KEY,
  model: "gemini-2.0-flash-exp",
  temperature: 0.7,  // CrÃ©ativitÃ© : 0 = dÃ©terministe, 1 = crÃ©atif
});

// Utiliser le modÃ¨le
const result = await model.invoke("Quelle est la capitale de la France ?");
console.log(result.content);  // â†’ "La capitale de la France est Paris."
```

**Avantages** :
- Interface unifiÃ©e pour tous les LLMs
- Facile de changer de modÃ¨le (GPT â†’ Claude â†’ Gemini)
- Gestion automatique des requÃªtes/rÃ©ponses
- Retry automatique en cas d'erreur

#### 2. Prompts (Templates)

GÃ©rer et rÃ©utiliser des prompts complexes.

```typescript
import { ChatPromptTemplate } from "@langchain/core/prompts";

// CrÃ©er un template de prompt
const promptTemplate = ChatPromptTemplate.fromMessages([
  ["system", "Tu es un assistant de voyage spÃ©cialisÃ© en {specialty}."],
  ["user", "CrÃ©e un itinÃ©raire pour {destination} en {duration} jours."]
]);

// Utiliser le template
const prompt = await promptTemplate.format({
  specialty: "voyages culturels",
  destination: "Tokyo",
  duration: 3
});

const result = await model.invoke(prompt);
```

**Avantages** :
- Prompts rÃ©utilisables
- Variables dynamiques
- Versionning des prompts
- SÃ©paration prompt / logique

#### 3. Tools (Outils)

Donner au LLM des capacitÃ©s externes.

```typescript
import { tool } from "@langchain/core/tools";
import { z } from "zod";

// DÃ©finir un tool
const weatherTool = tool(
  async ({ city }) => {
    const response = await fetch(`https://api.weather.com/${city}`);
    const data = await response.json();
    return `TempÃ©rature Ã  ${city}: ${data.temp}Â°C`;
  },
  {
    name: "get_weather",
    description: "Obtenir la mÃ©tÃ©o pour une ville",
    schema: z.object({
      city: z.string().describe("Nom de la ville")
    })
  }
);

// Le LLM peut maintenant "appeler" ce tool
```

#### 4. Chains (ChaÃ®nes)

SÃ©quencer plusieurs opÃ©rations.

```typescript
import { LLMChain } from "langchain/chains";

// ChaÃ®ne simple : prompt â†’ LLM
const chain = new LLMChain({
  llm: model,
  prompt: promptTemplate
});

const result = await chain.call({
  destination: "Tokyo",
  duration: 3
});
```

### Utilisation Simple dans le Projet

**Exemple : Travel Planner Agent**

Fichier : `src/agents/travel-planner-agent/executor.ts`

```typescript
import { ChatGoogleGenerativeAI } from "@langchain/google-genai";

export class TravelPlannerAgentExecutor {
  private model: ChatGoogleGenerativeAI;

  constructor() {
    // CrÃ©er le modÃ¨le Gemini
    this.model = new ChatGoogleGenerativeAI({
      apiKey: process.env.GEMINI_API_KEY!,
      model: "gemini-2.0-flash-exp",
      temperature: 0.7
    });
  }

  private async generateItinerary(
    departure: string,
    destination: string,
    activitiesInfo: string,
    weatherInfo: string,
    budgetInfo: string
  ): Promise<string> {
    // Construire le prompt
    const prompt = `Create a 1-day travel itinerary from ${departure} to ${destination}.

Context:
- Activities: ${activitiesInfo}
- Weather: ${weatherInfo}
- Budget: ${budgetInfo}

Include morning, afternoon, and evening activities.`;

    // Appeler le LLM
    const result = await this.model.invoke(prompt);
    return result.content as string;
  }
}
```

**Ce qui se passe** :
1. `ChatGoogleGenerativeAI` : wrapper LangChain pour Gemini
2. `invoke()` : mÃ©thode standardisÃ©e pour appeler le LLM
3. RÃ©sultat retournÃ© dans un format unifiÃ©

**Pourquoi LangChain ici ?**
- Simplifie l'appel Ã  Gemini (pas besoin de gÃ©rer l'API directement)
- Interface standardisÃ©e (facile de changer de modÃ¨le)
- Gestion automatique des erreurs et retry

---

## Qu'est-ce que LangGraph ?

### DÃ©finition

**LangGraph** est une extension de LangChain pour crÃ©er des **workflows multi-agents avec Ã©tat** (stateful multi-agent workflows). C'est comme un "graphe" oÃ¹ chaque nÅ“ud reprÃ©sente une action.

### DiffÃ©rence avec LangChain

| Aspect | LangChain | LangGraph |
|--------|-----------|-----------|
| **Usage** | Appeler LLMs, gÃ©rer prompts | Orchestrer workflows complexes |
| **Ã‰tat** | Stateless (sans mÃ©moire) | Stateful (avec mÃ©moire) |
| **Structure** | ChaÃ®nes linÃ©aires | Graphes avec branches |
| **ComplexitÃ©** | Simple | AvancÃ© |
| **Cas d'usage** | GÃ©nÃ©ration de texte | Agents autonomes, multi-steps |

### Architecture LangGraph

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              LangGraph Workflow                 â”‚
â”‚                                                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                  â”‚
â”‚   â”‚  Start  â”‚                                  â”‚
â”‚   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                                  â”‚
â”‚        â”‚                                        â”‚
â”‚        â–¼                                        â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                  â”‚
â”‚   â”‚  Agent  â”‚  â† Raisonne : quel tool ?       â”‚
â”‚   â”‚ (LLM)   â”‚                                  â”‚
â”‚   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                                  â”‚
â”‚        â”‚                                        â”‚
â”‚        â–¼                                        â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                  â”‚
â”‚   â”‚  Tool   â”‚  â† ExÃ©cute le tool               â”‚
â”‚   â”‚ Call    â”‚                                  â”‚
â”‚   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                                  â”‚
â”‚        â”‚                                        â”‚
â”‚        â–¼                                        â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                  â”‚
â”‚   â”‚  Agent  â”‚  â† Analyse le rÃ©sultat           â”‚
â”‚   â”‚ (LLM)   â”‚                                  â”‚
â”‚   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                                  â”‚
â”‚        â”‚                                        â”‚
â”‚   â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”                                  â”‚
â”‚   â”‚TerminÃ©? â”‚                                  â”‚
â”‚   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                                  â”‚
â”‚        â”‚ Non â†’ Retour Ã  "Tool Call"            â”‚
â”‚        â”‚ Oui â†“                                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                  â”‚
â”‚   â”‚   End   â”‚                                  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                  â”‚
â”‚                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Pattern ReAct

LangGraph implÃ©mente le pattern **ReAct** (Reasoning + Acting) :

1. **Reason** : le LLM raisonne sur l'action Ã  prendre
2. **Act** : le LLM appelle un tool
3. **Observe** : le LLM observe le rÃ©sultat du tool
4. **Repeat** : rÃ©pÃ¨te jusqu'Ã  avoir la rÃ©ponse finale

**Exemple de cycle ReAct** :

```
User : "Calculate the budget for 7 nights at $150/night with $25/day meals"

â”Œâ”€ Cycle 1 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Reason : "Je dois calculer un budget de voyage"â”‚
â”‚ Act    : call tool "calculate_trip_budget"     â”‚
â”‚          args: {nights: 7, price: 150, meals:25}â”‚
â”‚ Observe: "$1225 (Accommodation: $1050, ...)"   â”‚
â”‚ Reason : "J'ai le rÃ©sultat, je peux rÃ©pondre"  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Response : "The total budget is $1225..."
```

---

## LangChain vs LangGraph

### Comparaison DÃ©taillÃ©e

| CritÃ¨re | LangChain | LangGraph |
|---------|-----------|-----------|
| **Objectif** | Appeler LLMs et tools | CrÃ©er des agents autonomes |
| **ComplexitÃ©** | Simple | AvancÃ© |
| **Ã‰tat** | Pas de mÃ©moire entre appels | Garde l'Ã©tat du workflow |
| **Pattern** | ChaÃ®nes linÃ©aires | Graphes avec boucles |
| **Tools** | Peut utiliser des tools | Agents qui choisissent les tools |
| **Use case** | GÃ©nÃ©ration de texte simple | Agents qui raisonnent et agissent |

### Quand Utiliser Quoi ?

#### Utiliser LangChain (simple) quand :

âœ… Vous voulez juste **appeler un LLM** pour gÃ©nÃ©rer du texte
âœ… Pas besoin de tools
âœ… Workflow linÃ©aire (A â†’ B â†’ C)
âœ… Pas besoin de mÃ©moire entre Ã©tapes

**Exemple du projet** : Travel Planner gÃ©nÃ¨re un itinÃ©raire

```typescript
// Simple : juste appeler Gemini
const result = await this.model.invoke(prompt);
return result.content as string;
```

#### Utiliser LangGraph (avancÃ©) quand :

âœ… Vous voulez un **agent autonome** qui dÃ©cide quoi faire
âœ… L'agent doit **choisir parmi plusieurs tools**
âœ… Workflow avec **boucles** (rÃ©essayer, itÃ©rer)
âœ… Besoin de **mÃ©moire** entre Ã©tapes

**Exemple du projet** : Calculator Agent choisit le bon tool mathÃ©matique

```typescript
// AvancÃ© : agent qui dÃ©cide quel tool utiliser
const agent = createReactAgent({
  llm: this.model,
  tools: [addTool, multiplyTool, budgetTool]
});

const result = await agent.invoke({
  messages: [{ role: "user", content: "Calculate 150 + 75" }]
});
// L'agent choisit automatiquement le tool "add"
```

### Diagramme de DÃ©cision

```
Votre besoin
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Besoin d'un agent   â”‚
â”‚ qui choisit parmi   â”‚  Oui
â”‚ plusieurs tools ?   â”œâ”€â”€â”€â”€â”€â”€â”€â”€> LangGraph + createReactAgent
â”‚                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚ Non
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Juste gÃ©nÃ©rer du    â”‚  Oui
â”‚ texte avec un LLM ? â”œâ”€â”€â”€â”€â”€â”€â”€â”€> LangChain (model.invoke)
â”‚                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Utilisation dans le Projet

### Vue d'Ensemble

| Agent | LangChain | LangGraph | Tools | Pattern |
|-------|-----------|-----------|-------|---------|
| **Travel Planner** | âœ… | âŒ | âŒ | Simple invoke |
| **Calculator** | âœ… | âœ… | âœ… MCP | ReAct Agent |
| **Web Search** | âœ… | âœ… | âœ… MCP | ReAct Agent |
| **Translator** | âŒ | âŒ | âŒ | Direct Gemini SDK |
| **Weather** | âŒ | âŒ | âŒ | Direct API |

### Pattern 1 : LangChain Simple (Travel Planner)

**Besoin** : GÃ©nÃ©rer un itinÃ©raire de voyage avec contexte

**Solution** : LangChain uniquement

```typescript
// CrÃ©er le modÃ¨le
this.model = new ChatGoogleGenerativeAI({
  apiKey: process.env.GEMINI_API_KEY,
  model: "gemini-2.0-flash-exp",
  temperature: 0.7
});

// Construire un prompt avec contexte
const prompt = `Create itinerary from ${departure} to ${destination}.
Context:
- Activities: ${activitiesInfo}
- Weather: ${weatherInfo}
- Budget: ${budgetInfo}`;

// Appeler le modÃ¨le
const result = await this.model.invoke(prompt);
```

**Pourquoi ce pattern ?**
- Pas besoin de tools (juste gÃ©nÃ©ration de texte)
- Workflow simple et linÃ©aire
- LangChain simplifie l'appel Ã  Gemini

### Pattern 2 : LangGraph + MCP (Calculator Agent)

**Besoin** : Agent qui choisit automatiquement le bon tool mathÃ©matique

**Solution** : LangGraph avec ReAct Agent

```typescript
import { ChatGoogleGenerativeAI } from "@langchain/google-genai";
import { createReactAgent } from "@langchain/langgraph/prebuilt";
import { loadMcpTools } from "@langchain/mcp-adapters";

// 1. CrÃ©er le LLM
this.model = new ChatGoogleGenerativeAI({
  apiKey: process.env.GEMINI_API_KEY,
  model: "gemini-2.0-flash-exp",
  temperature: 0  // DÃ©terministe pour calculs
});

// 2. Connecter au serveur MCP
this.mcpClient = new Client(...);
await this.mcpClient.connect(transport);

// 3. Charger les tools MCP
const tools = await loadMcpTools("custom-math", this.mcpClient);
// â†’ [addTool, multiplyTool, calculate_trip_budget]

// 4. CrÃ©er l'agent ReAct
this.agent = createReactAgent({
  llm: this.model,
  tools: tools
});

// 5. Utiliser l'agent
const result = await this.agent.invoke({
  messages: [{ role: "user", content: "Calculate 7 nights at $150/night + $25/day meals" }]
});

// L'agent va :
// - Raisonner : "Je dois utiliser calculate_trip_budget"
// - Appeler : calculate_trip_budget(7, 150, 25)
// - Observer : "$1225"
// - RÃ©pondre : "The total budget is $1225..."
```

**Pourquoi ce pattern ?**
- Agent doit **choisir** parmi 3 tools (add, multiply, calculate_trip_budget)
- LLM dÃ©cide automatiquement quel tool utiliser
- Pas besoin de logique if/else pour choisir le tool

---

## IntÃ©gration avec Gemini

### ChatGoogleGenerativeAI

LangChain fournit un wrapper pour Google Gemini.

```typescript
import { ChatGoogleGenerativeAI } from "@langchain/google-genai";

const model = new ChatGoogleGenerativeAI({
  apiKey: process.env.GEMINI_API_KEY,  // ClÃ© API Google
  model: "gemini-2.0-flash-exp",       // ModÃ¨le Ã  utiliser
  temperature: 0.7,                     // 0 = dÃ©terministe, 1 = crÃ©atif
  maxOutputTokens: 2048,                // Limite de tokens en sortie
  topP: 0.9,                            // Sampling (optionnel)
  topK: 40                              // Sampling (optionnel)
});
```

### ParamÃ¨tres Importants

| ParamÃ¨tre | Description | Valeur RecommandÃ©e |
|-----------|-------------|-------------------|
| **model** | ModÃ¨le Gemini Ã  utiliser | `gemini-2.0-flash-exp` (rapide) ou `gemini-pro` (puissant) |
| **temperature** | CrÃ©ativitÃ© du modÃ¨le | `0` = calculs prÃ©cis, `0.7` = gÃ©nÃ©ration crÃ©ative, `1` = trÃ¨s crÃ©atif |
| **maxOutputTokens** | Limite de tokens gÃ©nÃ©rÃ©s | `2048` par dÃ©faut, augmenter si besoin de longs textes |

### MÃ©thodes Principales

#### 1. invoke() : Appel Simple

```typescript
const result = await model.invoke("Quelle est la capitale de la France ?");
console.log(result.content);  // â†’ "La capitale de la France est Paris."
```

#### 2. stream() : Streaming

```typescript
const stream = await model.stream("Raconte-moi une histoire");

for await (const chunk of stream) {
  process.stdout.write(chunk.content);  // Affiche mot par mot
}
```

#### 3. batch() : Batch Processing

```typescript
const results = await model.batch([
  "Capitale de la France ?",
  "Capitale de l'Allemagne ?",
  "Capitale de l'Italie ?"
]);

// â†’ ["Paris", "Berlin", "Rome"]
```

---

## ReAct Agent Pattern

### Qu'est-ce que ReAct ?

**ReAct** = **Rea**soning (Raisonnement) + **Act**ing (Action)

C'est un pattern oÃ¹ l'agent :
1. **Raisonne** : analyse la situation et dÃ©cide quoi faire
2. **Agit** : exÃ©cute une action (appeler un tool)
3. **Observe** : regarde le rÃ©sultat
4. **RÃ©pÃ¨te** : continue jusqu'Ã  avoir la rÃ©ponse

### Diagramme ReAct

```
User: "Calculate trip budget for 7 nights at $150/night with $25/day meals"
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 1: Reason (Raisonnement)                            â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â”‚
â”‚  LLM pense : "L'utilisateur veut un budget de voyage.    â”‚
â”‚               J'ai 3 tools disponibles : add, multiply,   â”‚
â”‚               calculate_trip_budget.                      â”‚
â”‚               Le tool appropriÃ© est calculate_trip_budget"â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 2: Act (Action)                                     â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â”‚
â”‚  LLM dÃ©cide d'appeler :                                   â”‚
â”‚  Tool: calculate_trip_budget                              â”‚
â”‚  Args: { nights: 7, pricePerNight: 150, mealsPerDay: 25 }â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 3: Tool Execution (via MCP)                         â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â”‚
â”‚  Math Server exÃ©cute :                                    â”‚
â”‚  - Accommodation: 7 Ã— 150 = 1050                          â”‚
â”‚  - Meals: 7 Ã— 25 = 175                                    â”‚
â”‚  - Total: 1050 + 175 = 1225                               â”‚
â”‚  â†’ Retour: "Total trip budget: $1225 (...)"              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 4: Observe (Observation)                            â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â”‚
â”‚  LLM reÃ§oit le rÃ©sultat du tool :                         â”‚
â”‚  "Total trip budget: $1225 (Accommodation: $1050, ...)"  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 5: Reason Again (Re-raisonnement)                   â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â”‚
â”‚  LLM pense : "J'ai le rÃ©sultat du calcul.                â”‚
â”‚               Je peux maintenant rÃ©pondre Ã  l'utilisateur"â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 6: Final Response                                   â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â”‚
â”‚  "The total trip budget is $1225, which includes $1050   â”‚
â”‚   for accommodation (7 nights at $150/night) and $175    â”‚
â”‚   for meals (7 days at $25/day)."                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### CrÃ©er un Agent ReAct

```typescript
import { createReactAgent } from "@langchain/langgraph/prebuilt";

const agent = createReactAgent({
  llm: model,        // Le LLM qui raisonne
  tools: tools,      // Les tools disponibles
  messageModifier: systemPrompt  // Optionnel : instructions systÃ¨me
});
```

**ParamÃ¨tres** :

- **llm** : l'instance du LLM (ChatGoogleGenerativeAI)
- **tools** : array de tools que l'agent peut utiliser
- **messageModifier** : optionnel, instructions systÃ¨me pour guider l'agent

### Invoquer l'Agent

```typescript
const result = await agent.invoke({
  messages: [
    { role: "user", content: "Calculate 150 + 75" }
  ]
});

// Extraire la rÃ©ponse
const response = result.messages[result.messages.length - 1].content;
console.log(response);  // â†’ "150 + 75 = 225"
```

**Structure de la rÃ©ponse** :

```typescript
{
  messages: [
    { role: "user", content: "Calculate 150 + 75" },
    { role: "assistant", content: "I need to use the add tool", tool_calls: [...] },
    { role: "tool", content: "225", tool_call_id: "..." },
    { role: "assistant", content: "150 + 75 = 225" }
  ]
}
```

L'agent retourne **tous les messages** de la conversation interne (raisonnement + appels tools + rÃ©sultats).

---

## MCP Adapters pour LangChain

### Qu'est-ce que MCP Adapters ?

**MCP Adapters** (`@langchain/mcp-adapters`) est un package qui permet de **charger des tools MCP** et de les utiliser avec LangChain/LangGraph.

### Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          LangChain / LangGraph                  â”‚
â”‚                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚        ReAct Agent                       â”‚  â”‚
â”‚  â”‚   (LLM qui choisit les tools)            â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                    â”‚                            â”‚
â”‚                    â”‚ Utilise                    â”‚
â”‚                    â–¼                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚      LangChain Tools                     â”‚  â”‚
â”‚  â”‚   (format LangChain standard)            â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â”‚ ChargÃ©s via loadMcpTools()
                     â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          @langchain/mcp-adapters                â”‚
â”‚   (Convertit MCP tools â†’ LangChain tools)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â”‚ Communique via MCP Client
                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            MCP Server                           â”‚
â”‚   (Math Server, Brave Search, etc.)             â”‚
â”‚   - Expose des tools MCP                        â”‚
â”‚   - ExÃ©cute les fonctions                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### loadMcpTools()

Fonction pour charger les tools depuis un serveur MCP.

```typescript
import { loadMcpTools } from "@langchain/mcp-adapters";
import { Client } from "@modelcontextprotocol/sdk/client/index.js";

// 1. CrÃ©er et connecter le client MCP
const mcpClient = new Client({ name: "my-client", version: "1.0.0" }, { capabilities: {} });
await mcpClient.connect(transport);

// 2. Charger les tools
const tools = await loadMcpTools("server-name", mcpClient);

// 3. Les tools sont maintenant au format LangChain
console.log(tools.length);  // â†’ 3
console.log(tools[0].name);  // â†’ "add"
console.log(tools[1].name);  // â†’ "multiply"
console.log(tools[2].name);  // â†’ "calculate_trip_budget"
```

**Ce qui se passe** :

1. `loadMcpTools()` appelle le serveur MCP : `ListToolsRequest`
2. Le serveur retourne la liste des tools (nom, description, schÃ©ma)
3. `loadMcpTools()` convertit chaque tool MCP en tool LangChain
4. Les tools peuvent maintenant Ãªtre utilisÃ©s par un agent LangChain/LangGraph

### Format de Tool

**MCP Tool** (cÃ´tÃ© serveur) :

```typescript
{
  name: "add",
  description: "Add two numbers",
  inputSchema: {
    type: "object",
    properties: {
      a: { type: "number" },
      b: { type: "number" }
    },
    required: ["a", "b"]
  }
}
```

**LangChain Tool** (aprÃ¨s conversion) :

```typescript
{
  name: "add",
  description: "Add two numbers",
  schema: z.object({
    a: z.number(),
    b: z.number()
  }),
  func: async (args) => {
    // Appelle le serveur MCP avec CallToolRequest
    const result = await mcpClient.callTool("add", args);
    return result.content[0].text;
  }
}
```

---

## Exemples Concrets du Projet

### Exemple 1 : Travel Planner (LangChain Simple)

**Fichier** : `src/agents/travel-planner-agent/executor.ts`

```typescript
import { ChatGoogleGenerativeAI } from "@langchain/google-genai";

export class TravelPlannerAgentExecutor implements AgentExecutor {
  private model: ChatGoogleGenerativeAI | null = null;
  private useMock: boolean;

  constructor() {
    this.useMock = process.env.USE_MOCK_DATA === "true";

    if (!this.useMock) {
      // CrÃ©er le modÃ¨le Gemini via LangChain
      this.model = new ChatGoogleGenerativeAI({
        apiKey: process.env.GEMINI_API_KEY!,
        model: "gemini-2.0-flash-exp",
        temperature: 0.7
      });
    }
  }

  private async generateItinerary(
    departure: string,
    destination: string,
    activitiesInfo: string,
    weatherInfo: string,
    budgetInfo: string
  ): Promise<string> {
    console.log(`[Travel Planner] Generating itinerary`);

    // Mode mock : retourner donnÃ©es prÃ©-dÃ©finies
    if (this.useMock) {
      await new Promise((resolve) => setTimeout(resolve, 2000));
      return getMockItinerary(departure, destination);
    }

    // Construire le prompt avec contexte
    const itineraryPrompt = `Create a 1-day travel itinerary from ${departure} to ${destination}.

Context:
- Activities: ${activitiesInfo}
- Weather: ${weatherInfo}
- Budget: ${budgetInfo}

Include morning, afternoon, and evening activities. Keep it simple and concise.`;

    // Appeler Gemini via LangChain
    const result = await this.model!.invoke(itineraryPrompt);
    return result.content as string;
  }
}
```

**Utilisation** :

```
Travel Planner reÃ§oit : "Tokyo, Paris, French"
  â†“
1. Orchestre tous les agents pour rÃ©cupÃ©rer :
   - activitiesInfo (Web Search Agent)
   - weatherInfo (Weather Agent)
   - budgetInfo (Calculator Agent)
  â†“
2. Appelle generateItinerary() avec tout le contexte
  â†“
3. LangChain â†’ Gemini : gÃ©nÃ¨re l'itinÃ©raire
  â†“
4. Retourne : "Morning: Visit Senso-ji Temple..."
```

**Pourquoi LangChain ?**
- Simplifie l'appel Ã  Gemini (pas besoin de gÃ©rer l'API REST)
- Interface unifiÃ©e (facile de changer de modÃ¨le)
- Gestion automatique des erreurs

---

### Exemple 2 : Calculator Agent (LangGraph + MCP)

**Fichier** : `src/agents/calculator-agent/executor.ts`

```typescript
import { ChatGoogleGenerativeAI } from "@langchain/google-genai";
import { createReactAgent } from "@langchain/langgraph/prebuilt";
import { loadMcpTools } from "@langchain/mcp-adapters";
import { Client } from "@modelcontextprotocol/sdk/client/index.js";
import { StdioClientTransport } from "@modelcontextprotocol/sdk/client/stdio.js";

export class CalculatorAgentExecutor implements AgentExecutor {
  private model: ChatGoogleGenerativeAI;
  private mcpClient: Client | null = null;
  private agent: any = null;

  constructor() {
    // CrÃ©er le LLM Gemini
    this.model = new ChatGoogleGenerativeAI({
      apiKey: process.env.GEMINI_API_KEY!,
      model: "gemini-2.0-flash-exp",
      temperature: 0  // DÃ©terministe pour calculs
    });
  }

  private async initializeMcpAgent() {
    if (this.agent) return this.agent;

    console.log("[Calculator Agent] Initializing MCP connection...");

    // 1. CrÃ©er le client MCP
    this.mcpClient = new Client(
      { name: "calculator-client", version: "1.0.0" },
      { capabilities: {} }
    );

    // 2. Se connecter au Math Server via stdio
    const serverPath = path.join(process.cwd(), "dist", "mcp-servers", "math-server.js");
    const transport = new StdioClientTransport({
      command: "node",
      args: [serverPath]
    });
    await this.mcpClient.connect(transport);

    console.log("[Calculator Agent] MCP connected");

    // 3. Charger les tools MCP (convertis en tools LangChain)
    const tools = await loadMcpTools("custom-math", this.mcpClient);
    console.log(`[Calculator Agent] Loaded ${tools.length} tools`);
    // â†’ 3 tools : add, multiply, calculate_trip_budget

    // 4. CrÃ©er l'agent ReAct avec LangGraph
    this.agent = createReactAgent({
      llm: this.model,
      tools: tools
    });

    console.log("[Calculator Agent] Agent initialized");
    return this.agent;
  }

  async execute(
    requestContext: RequestContext,
    eventBus: ExecutionEventBus
  ): Promise<void> {
    try {
      const userText = requestContext.userMessage.parts.find((p) => p.kind === "text")?.text || "";
      console.log(`[Calculator Agent] Processing: ${userText}`);

      // Initialiser l'agent MCP
      const agent = await this.initializeMcpAgent();

      // Invoquer l'agent
      // L'agent va automatiquement :
      // 1. Raisonner : quel tool utiliser ?
      // 2. Appeler le tool via MCP
      // 3. Formuler la rÃ©ponse
      const result = await agent.invoke({
        messages: [{ role: "user", content: userText }]
      });

      // Extraire la rÃ©ponse finale
      const agentResponse = result.messages[result.messages.length - 1].content;

      console.log(`[Calculator Agent] Calculation completed`);

      // Publier la rÃ©ponse via A2A
      eventBus.publish({
        kind: "message",
        messageId: uuidv4(),
        role: "agent",
        parts: [{ kind: "text", text: agentResponse }],
        contextId: requestContext.userMessage.contextId,
        taskId: requestContext.task?.id || uuidv4()
      });
      eventBus.finished();

    } catch (error: any) {
      console.error("[Calculator Agent] Error:", error);
      // Publier erreur...
    }
  }
}
```

**Flow complet** :

```
User: "Calculate trip budget for 7 nights at $150/night with $25/day meals"
  â†“
Travel Planner â†’ Calculator Agent (A2A)
  â†“
Calculator Agent:
  1. initializeMcpAgent()
     - Connecte au Math Server (stdio)
     - Charge 3 tools MCP â†’ convertis en tools LangChain
     - CrÃ©e agent ReAct (LangGraph)
  â†“
  2. agent.invoke({ messages: [{ role: "user", content: "Calculate..." }] })
     â†“
     LLM (Gemini) raisonne :
     "Je dois utiliser calculate_trip_budget"
     â†“
     LangGraph appelle le tool :
     calculate_trip_budget(nights=7, pricePerNight=150, mealsPerDay=25)
     â†“
     MCP Client â†’ Math Server (stdio)
     â†“
     Math Server calcule : 1050 + 175 = 1225
     â†“
     Math Server â†’ MCP Client : "Total: $1225"
     â†“
     LLM formule rÃ©ponse : "The total trip budget is $1225..."
  â†“
  3. Publier rÃ©ponse via A2A EventBus
  â†“
Travel Planner reÃ§oit : "Total trip budget: $1225..."
```

**Pourquoi LangGraph + MCP ?**
- **LangGraph** : agent qui choisit automatiquement le bon tool
- **MCP** : tools mathÃ©matiques prÃ©cis et rÃ©utilisables
- **LangChain** : interface unifiÃ©e pour LLM + tools

---

### Exemple 3 : Web Search Agent (LangGraph + Brave MCP)

**Fichier** : `src/agents/web-search-agent/executor.ts`

MÃªme pattern que Calculator Agent, mais avec Brave Search au lieu de Math.

```typescript
// 1. Connecter au serveur Brave Search MCP
this.mcpClient = new Client(...);
await this.mcpClient.connect(transport);

// 2. Charger les tools de recherche
const tools = await loadMcpTools("brave-search", this.mcpClient);
// â†’ brave_web_search, brave_local_search

// 3. CrÃ©er l'agent ReAct
this.agent = createReactAgent({
  llm: this.model,
  tools: tools
});

// 4. L'agent choisit automatiquement quel type de recherche utiliser
const result = await this.agent.invoke({
  messages: [{ role: "user", content: "best things to do in Tokyo" }]
});
```

---

## RÃ©sumÃ© et Bonnes Pratiques

### Points ClÃ©s Ã  Retenir

| Concept | Description | Usage Projet |
|---------|-------------|--------------|
| **LangChain** | Framework pour appeler LLMs | Travel Planner (gÃ©nÃ©ration itinÃ©raire) |
| **LangGraph** | Extension pour agents autonomes | Calculator, Web Search (agents ReAct) |
| **ChatGoogleGenerativeAI** | Wrapper LangChain pour Gemini | Tous les agents utilisant Gemini |
| **createReactAgent** | CrÃ©er un agent ReAct | Calculator, Web Search |
| **loadMcpTools** | Charger tools MCP dans LangChain | Calculator (Math), Web Search (Brave) |
| **ReAct Pattern** | Reasoning + Acting en boucle | Agents qui choisissent des tools |

### Quand Utiliser Quoi ?

#### Pattern 1 : LangChain Simple

```typescript
// Juste gÃ©nÃ©rer du texte
const model = new ChatGoogleGenerativeAI({...});
const result = await model.invoke(prompt);
```

**UtilisÃ© par** : Travel Planner

**Quand** :
- Pas besoin de tools
- GÃ©nÃ©ration de texte simple
- Workflow linÃ©aire

#### Pattern 2 : LangGraph + MCP

```typescript
// Agent autonome avec tools
const model = new ChatGoogleGenerativeAI({...});
const tools = await loadMcpTools("server-name", mcpClient);
const agent = createReactAgent({ llm: model, tools });
const result = await agent.invoke({...});
```

**UtilisÃ© par** : Calculator, Web Search

**Quand** :
- Agent doit choisir parmi plusieurs tools
- Besoin de raisonnement dynamique
- Tools via MCP

### Checklist : IntÃ©grer LangChain/LangGraph

#### LangChain Simple

- [ ] Installer : `npm install @langchain/google-genai`
- [ ] CrÃ©er le modÃ¨le : `new ChatGoogleGenerativeAI({...})`
- [ ] Appeler : `await model.invoke(prompt)`
- [ ] Extraire rÃ©ponse : `result.content`

#### LangGraph + MCP

- [ ] Installer : `npm install @langchain/google-genai @langchain/langgraph @langchain/mcp-adapters`
- [ ] CrÃ©er le modÃ¨le : `new ChatGoogleGenerativeAI({...})`
- [ ] CrÃ©er client MCP : `new Client({...})`
- [ ] Connecter au serveur MCP : `await client.connect(transport)`
- [ ] Charger tools : `await loadMcpTools("name", client)`
- [ ] CrÃ©er agent : `createReactAgent({ llm, tools })`
- [ ] Invoquer : `await agent.invoke({ messages: [...] })`
- [ ] Extraire rÃ©ponse : `result.messages[result.messages.length - 1].content`

### PiÃ¨ges Ã  Ã‰viter

âŒ **Utiliser LangGraph pour gÃ©nÃ©ration simple**

```typescript
// âŒ Mauvais : overkill pour juste gÃ©nÃ©rer du texte
const agent = createReactAgent({ llm: model, tools: [] });
const result = await agent.invoke({...});
```

```typescript
// âœ… Bon : LangChain simple suffit
const result = await model.invoke(prompt);
```

âŒ **Ne pas gÃ©rer les erreurs MCP**

```typescript
// âŒ Mauvais : pas de gestion d'erreur
const tools = await loadMcpTools("server", client);
```

```typescript
// âœ… Bon : try/catch
try {
  const tools = await loadMcpTools("server", client);
} catch (error) {
  console.error("Failed to load MCP tools:", error);
  // Fallback ou mode mock
}
```

âŒ **TempÃ©rature trop Ã©levÃ©e pour calculs**

```typescript
// âŒ Mauvais : crÃ©atif = imprÃ©cis
const model = new ChatGoogleGenerativeAI({
  temperature: 0.9  // Trop crÃ©atif pour calculs !
});
```

```typescript
// âœ… Bon : dÃ©terministe pour prÃ©cision
const model = new ChatGoogleGenerativeAI({
  temperature: 0  // DÃ©terministe
});
```

### Comparaison Finale

| Besoin | Solution | Package |
|--------|----------|---------|
| Appeler Gemini simplement | `ChatGoogleGenerativeAI` | `@langchain/google-genai` |
| GÃ©nÃ©rer texte avec LLM | `model.invoke()` | `@langchain/google-genai` |
| Agent qui choisit tools | `createReactAgent()` | `@langchain/langgraph` |
| Charger tools MCP | `loadMcpTools()` | `@langchain/mcp-adapters` |

### Architecture ComplÃ¨te du Projet

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Travel Planner                       â”‚
â”‚                                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  LangChain (Simple)                              â”‚ â”‚
â”‚  â”‚  - ChatGoogleGenerativeAI                        â”‚ â”‚
â”‚  â”‚  - model.invoke(prompt)                          â”‚ â”‚
â”‚  â”‚  - GÃ©nÃ¨re itinÃ©raire                             â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â”‚ Orchestre (A2A)
          â”‚
   â”Œâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚      â”‚        â”‚            â”‚
   â–¼      â–¼        â–¼            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Weatherâ”‚â”‚Transâ”‚â”‚ Web  â”‚â”‚     Calculator Agent          â”‚
â”‚      â”‚â”‚latorâ”‚â”‚Searchâ”‚â”‚                               â”‚
â””â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”˜â”‚      â”‚â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
               â”‚      â”‚â”‚  â”‚ LangGraph + MCP         â”‚  â”‚
               â”‚      â”‚â”‚  â”‚ - createReactAgent()    â”‚  â”‚
               â”‚      â”‚â”‚  â”‚ - loadMcpTools()        â”‚  â”‚
               â”‚      â”‚â”‚  â”‚ - ReAct Pattern         â”‚  â”‚
               â”‚      â”‚â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
               â”‚      â”‚â”‚           â”‚                   â”‚
               â”‚      â”‚â”‚           â”‚ MCP               â”‚
               â”‚      â”‚â”‚           â–¼                   â”‚
               â”‚      â”‚â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
               â”‚      â”‚â”‚  â”‚   Math MCP Server       â”‚  â”‚
               â”‚      â”‚â”‚  â”‚   (add, multiply, ...)  â”‚  â”‚
               â”‚      â”‚â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
               â””â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â”‚ LangGraph + MCP (Brave)
                  â”‚
               â”Œâ”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚ Brave Search MCP Server â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Prochaines Ã‰tapes

Vous maÃ®trisez maintenant :

âœ… **LangChain** : appeler des LLMs simplement
âœ… **LangGraph** : crÃ©er des agents autonomes
âœ… **ReAct Pattern** : agents qui raisonnent et agissent
âœ… **MCP Adapters** : charger des tools MCP dans LangChain
âœ… **IntÃ©gration Gemini** : utiliser Google Gemini via LangChain
âœ… **Architecture du projet** : oÃ¹ et pourquoi utiliser chaque composant

---

**FÃ©licitations !** Vous comprenez maintenant comment LangChain et LangGraph sont utilisÃ©s dans le projet. ğŸ‰

**Fichier prÃ©cÃ©dent** : [05 - Guide Pratique du Projet](./05-project-walkthrough.md)
**Retour au dÃ©but** : [README](./README.md)
